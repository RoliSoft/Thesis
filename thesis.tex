\documentclass[a4paper,12pt]{article}

\usepackage[utf8x]{inputenc}
\usepackage[english,romanian,hungarian]{babel}
\usepackage[margin=1in]{geometry}

\usepackage{indentfirst}
\usepackage{fancyhdr}
\pagestyle{fancy}

\usepackage[backref=false,pagebackref=true]{hyperref}
\hypersetup{colorlinks=true,urlcolor=blue,pdfborder={0 0 0}}
\usepackage{multirow}
\usepackage[table,xcdraw]{xcolor}

\usepackage{graphicx}
\usepackage{wrapfig}

\usepackage{booktabs}
\usepackage{multicol}
\usepackage{amsmath}

\usepackage{enumitem}
\setlist[itemize]{itemsep=0pt}
\setlist[enumerate]{itemsep=0pt}

\setlength{\parindent}{2em}
\setlength{\parskip}{0.25em}

\renewcommand{\arraystretch}{2}

\newcommand{\urlprefix}{Retrieved from \urlstyle{rm}}

\newcommand{\refspace}{\vspace{-2mm}}
\newcommand{\redarrow}{\textcolor{red}{$\mathbf{\Rightarrow}$}}
\makeatletter
\def\BR@@bibitem#1#2\par{
	\let\backrefprint\BR@backrefprint
	\def\@linkcolor{black}
	\BRorg@bibitem{#1}#2\redarrow \thinspace \BR@backref{#1}
}
\makeatother

\definecolor{whitesmoke}{rgb}{0.96,0.96,0.96}

\usepackage[T1]{fontenc}
\usepackage{lmodern}

%\usepackage{listings}
%\lstset{basicstyle=\footnotesize,numbers=left,numberstyle=\scriptsize,numbersep=7pt,breaklines=true,breakatwhitespace=true,tabsize=4,backgroundcolor=\color{whitesmoke}}
% \begin{lstlisting}[language=c++,caption=...]
% \lstinline[language=c++]{...}

\usepackage{minted}
\renewcommand{\theFancyVerbLine}{\rmfamily\scriptsize\arabic{FancyVerbLine}}
\setminted{linenos,autogobble,breaklines,fontsize=\footnotesize,tabsize=4,numbersep=7pt,bgcolor=whitesmoke}
% \begin{minted}{cpp}
% \mintinline{cpp}{...}

\author{Roland Bogosi}
\title{Black-Box Penetration Testing and Vulnerability Management Platform}

\begin{document}

\thispagestyle{empty}
\selectlanguage{english}

	\begin{center}
		{\Large Sapientia University, Târgu-Mureș}\\\vspace{0.05in}
		{\Large Faculty of Technical and Human Sciences}\\\vspace{0.07in}
		{\Large Computer Engineering}\\
		
		\vspace{2.5in}
		
		{\huge Black-Box Penetration Testing and}\\\vspace{0.1in}
		{\huge Vulnerability Management Platform}
		
		\vspace{0.5in}
		
		{\LARGE Bachelor's Thesis}
		
	\end{center}
	
	\vspace{2.0in}
	
	\begin{multicols}{2}
		\begin{flushleft}
			{\Large Supervisor:}\\\vspace{0.05in}
			{\LARGE {Dr. Tamás Vajda}}
		\end{flushleft}
		\columnbreak
		\begin{flushright}
			{\Large Student:}\\\vspace{0.1in}
			{\LARGE {Roland Bogosi}}
		\end{flushright}
	\end{multicols}
	
	\vspace{1.5in}
		
	\begin{center}
		{\LARGE 2016}
	\end{center}

\newpage
\thispagestyle{empty}
\section*{Table of Contents}
\selectlanguage{english}

	\begingroup
	\renewcommand{\section}[2]{}
	\hypersetup{linkcolor=blue}
	\setlength{\parskip}{0em}
	\tableofcontents
	\endgroup

\newpage
\section{Introduction}

	As the world is embracing digital technologies more and more, a lot of our services are keeping up with this trend, and have started being digitally available for the purposes of easier and faster accessibility. Digital data can be processed much faster and reliably than its analogue equivalents, which benefits the service providers by keeping the costs of providing their services low. Customers are also saved the headache of experiencing routine unpleasantries which are now alleviated by digital services, such as queuing up in order to pay the bills for various services one has subscribed to.
	
	Service providers, however, are not the only consumers of the benefits handed to us by the Internet. Advancements made in the past decade in the fields of software, hardware and network connectivity, have led to an exponential growth in the number of devices connected to the Internet. Due to the boom of \textit{IoT}, (``\textit{Internet of Things}'') \textit{Cisco} predicts there will be 25 billion devices connected to the Internet by 2015, which number is expected to increase to 50 billion by 2020.\cite{devans11} The pool of unallocated IPv4 addresses was completely depleted when \textit{LACNIC} has allocated their last block on the 10th of June, 2014.\cite{ghouston11} This event symbolically signifies, that the Internet has become way too big for what it was initially envisioned in the 1960's.
	
	Our increasing reliance on digital services and data are not without its drawbacks, however. With more and more sensitive information and transactions being done over the Internet, one must question the security of it all. As one idiom states, ``\textit{a chain is as strong as its weakest link},'' and in the context of Internet-enabled applications, there are a lot of these aforementioned figurative ``\textit{links}.'' Starting from the possibility of there being an attack vector on any layer of the \textit{OSI} between the two communicating devices, down to the vulnerabilities which are specific to the application being executed over the network.
	
\subsection{Security Awareness of IT Professionals}
	
	As one study done by \textit{BSIMM-V} (\textit{Building Security In Maturity Model}) which included 51 top-tier firms (mostly fortune 500) has concluded\cite{gmcgraw12}, a large percentage of product managers, software developers and system administrators have never received security awareness training nor been instructed to lay an emphasis on security, and as a result they do not prioritize it. One of the reasons why one might \textit{not} consider security awareness to be a priority is due to bogusly thinking that security aware application development and deployment is too costly. A study done by the \textit{Aberdeen Group} has shown that companies who invest in security end up with up-to a four-fold \textit{ROI} (``\textit{Return on Investments}'').\cite{aberdeen11}
	
	Companies have a long history of showing ignorance instead of security awareness. They are continuously claiming that they are untouchable, however, this is simply not true and these companies have been proven wrong time and time again. One recent example would be \textit{General Motor}'s take on their Internet-connected cars, where their spokesperson claimed that their cars are not ``hackable'' due to the fact that their entertainment system is separate from the rest of the control systems. A vulnerability was found by two security researchers\cite{cmiller15} which allowed them to inject control messages into the car's CAN bus, effectively allowing them to take control over the car via either WiFi or GSM.
	
	Software developers who would like an introduction to security-aware development can look up many of the freely available resources, however, this is not a perfect substitute for the proper training and the appropriate mindset. In some of the times, a vulnerability that was introduced by a developer might not even be their own fault, as more factors come into play in such cases. A developer might be familiar with the quirks and security issues of a specific language/environment/stack, but then be required by circumstance to move out of their comfort zone and either implement a given task in a non-standard way, or in a language they are not familiar enough with.
	
	One such case would be a developer of a managed language (for example, C\#) be required to interface with a non-managed language (for example, a library written in C) in which case the developer is now expected to do memory management in a language that does not promote its language management tools for it is a managed language. If said library is more complex, there are very high chances, that the developer will overlook some aspects (or not be aware they must be considered in the first place) and undesirable consequences may start happening, such as memory leaks and buffer over/underflows. In such case, it is recommended that a seasoned developer write a wrapper for the specific library in \textit{C++/CLI} (successor of \textit{Managed-C++}), a language designed by Microsoft for the intent purpose\cite{hstutter06} of bridging the managed and unmanaged worlds.
	
	There are other special circumstances under this argument, for example situations in which the developer of the application might be security-aware, or a proper penetration testing/code review was done, but the proposed security fixes might impact performance, ease of use, or even cause minor to major discomfort for the users. In such cases, risk analysis will be done, and some of these proposed solutions will be rejected as being unjustifiably too obtrusive. It is not the \textit{right} course of action in such situations, but risk analysis[\ref{ssec:vulnriskanal}] is a pretty standard tool for decision makers.
	
	Another special case would be IoT device ideas that have been funded through the use of crowdfunding platforms. These platforms, such as Kickstarter or IndieGoGo, are the hotbed of young entrepreneurial spirits with fresh ideas wanting to procure enough money in order to have a chance at executing them. Early prototypes of these projects are generally crafted using existing prototyping boards, such as Arduinos and Raspberry PIs. Later, when the proof of concept has proven to be viable and the first batch is moved to manufacturing, a similar architecture is built so as to allow re-use of existing code. This generally means that experimental code written in an environment in which the developer might not be comfortable enough in, is now being shipped as production code. This practice has spawned in the past lots of devices that are vulnerable and might present a huge security risk.\cite{mstan14}
	
\subsection{Security Awareness of Home Users}
	
	As Internet-connected devices are becoming more and more affordable and easier to use, home users have started adopting more and more of these devices. Unfortunately home users never receive any sort of formal security awareness training, and as such are very easily persuaded to fall for any type of attack which could have been easily prevented had they received a minimal amount of training. Even though, best-practices are usually laid out in the manual of the software being used, users tend to apply ignorance\cite{jnielsen12} even in cases when important notices and warnings are being displayed on the interface of the software and automatically click the ``OK''/``Next'' buttons, whatever gets them to what they wanted to be doing in the first place.
	
	A study done by the \textit{Colorado State University} has had some interesting\cite{ahowe12} results. When testing a group of people self-identified as having \textit{high} to \textit{very high} security awareness, 68\% of them ignored certificate errors on an HTTPS connection, and tried to determine the legitimacy of the said site based only on its content.
	
	A similar survey done in the U.K. has determined\cite{sfurnell07} that 93\% of the surveyed users has had some sort of anti-virus software installed, but only 50\% have installed it for themselves, and while this last point would not be an issue in and of itself, only 37\% of the respondents were applying security patches to their operating system on an at least weekly basis.
	
	When it comes to devices designed for, and services provided to home users, the balance of ease of use and security always comes into play. Users would like an easy-to-use device or application and would rather sacrifice security in order for experiencing a mild discomfort. In one study, in the context of online banking, a user mentioned that two-factor authentication was ``\textit{not} worth spending 5 minutes for \$1.99 purchases''\cite{ecrist14}. In the same study, it is shown that only 27\% of the users have \textit{voluntarily} opted to use multi-factor authentication, when available.
	
\subsection{Security Assurance in Enterprise Environments}

	Security is of paramount importance in enterprise environments. In such an environment, hundreds if not thousands of users (employees) depend on the IT infrastructure, and it is business-critical for these services to be functioning and data to be accessible 24/7, otherwise minor to major losses might be incurred. These hundreds or thousands of employees will all have different levels of access, controlled by strict security policies on what they can and cannot do or access.
	
	Administrators of large organizations, however, generally have to face large amounts of bureaucracy, and need to justify every little change and downtime to their superiors. They are also on a fixed budget, which means they might not be able to use the proper tools for a requested change, or even not being able to upgrade to a more secure version of a software or operating system, as it is ``not in the budget'' and their justification is rejected, as the superiors do not deem it important enough. The fixed budget is generally kept at a given level for unforeseen expenditures, such as having to adapt to possible legislation changes (for example, regarding storing sensitive customer data) or coping with new business roadmaps, trends and visions.\cite{gkreiz06}
	
	Developing, deploying, and administering mission critical projects, are also faced with a few dilemmas, as their project has to stay afloat and secure for years to come, all while the world around them is evolving at an exponential pace.
	
	Both administrators of large organizations and developers of mission critical projects therefore opt for versions of software/operating system/libraries usually annotated with \textit{LTS} (``\textit{Long-Term Support}'') or \textit{LTSB} (``\textit{Long-Term Servicing Branch}''). These special versions are ``feature-frozen'', meaning no new features will be added and no bug-fixes will be made that break backwards compatibility, but they continue to receive security patches for a long period of time, usually in the terms of years. Unfortunately there is no known and widely adopted standard as to the expected longevity of such LTS branches, which results in the practice of each project making up its own rules that it deems reasonable enough.
	
	Use of these special LTS versions are crucial in these cases, as \textit{without} them, one would have to face a choice as to risk using up-to-date versions, or risk using the version with which it was originally deployed with:
	
	\begin{itemize}
		\item Using \textit{up-to-date} software might break the project due to modified behavior or deprecation of functionality. As such, mission critical projects might start misbehaving or breaking completely, which might result in damages.
		\item Using the version that was originally \textit{deployed with}, means that the software is not receiving any updates, which solves the issues that might present themselves down the road as outlined in the first point. However, no software is perfect, and without applying any security patches, the system now becomes vulnerable to any attacks that might be disclosed during the lifetime of the project.
	\end{itemize}
	
	One ``celebrity'' example for the aforementioned second point would be the \textit{Heartbleed} vulnerability in \textit{OpenSSL}. The project being a universal, highly platform-agnostic and trustworthy cryptography and PKI toolkit was the basis of the majority of daemon software which were using SSL/TLS sockets in the *NIX userland, and was also embedded in IoT devices that had any sort of web interface or have done cryptography in any way, shape or form. Every embedded device deployed with a vulnerable version of OpenSSL is now live and vulnerable, with no easy fix that can be applied by the vendor remotely, in most cases. This has been acknowledged by multiple leading networking gear vendors in statements saying ``Cisco and Juniper cannot just press a button and immediately replace the vulnerable software running on the machines.''\cite{jpaglier14}
	
\subsection{Security Assurance in the Financial Sector} \label{ssec:secassfinsec}

	\begin{wrapfigure}{r}{0.35\textwidth}
		\vspace{-10pt}
		\centering
		\includegraphics[scale=0.5]{pci.png}
		\caption{PCI Logo}
	\end{wrapfigure}

	In the financial sector, major card vendors (such as Visa and MasterCard) have joined forces in order to form a council called \textit{Payment Card Industry Security Standards Council} which would then set forth a list of strict rules and requirements for parties handling sensitive financial data. These are outlined in a document called \textit{PCI DSS}. (\textit{Payment Card Industry Data Security Standard})
	
	Any company handling sensitive card holder information (such as merchants, payment gateways, banks, etc.) of the participating card schemes (such as Visa and MasterCard) are required to be \textit{PCI Compliant}, which means they follow the rules and regulations set forth in the \textit{PCI DSS} document. Compliance is then assessed either by an external \textit{QSA} (\textit{Qualified Security Assessor}) or, when the company is processing smaller volumes of transactions, a \textit{SAQ} (\textit{Self-Assessment Questionnaire}) can be filled out by the responsible persons within the company. Compliances are re-assessed every year, and companies processing sensitive card holder information who are \textit{not} compliant will be fined by the card schemes for every month and occurrence of non-compliance.\cite{wfargo15}
	
	The aforementioned document lays out 12 major requirements\cite{pcidss31} each with its own set of checklists, in order to determine full compliance with them. For the purposes of this thesis, the following requirements will be examined and discussed:
	
	\begin{itemize}
		\item Requirement 6: ``Develop and maintain secure systems and applications''
		\item Requirement 11: ``Regularly test security systems and processes''
	\end{itemize}
	
	Both of these requirements have rules whose execution goes beyond the complexity that a few check boxes can convey, and as such have supplemental information available on the website of the council, in order to further clarify what the compliance requirements mean, address frequently asked questions and close eventual loopholes.
	
	The section regarding the development and maintenance of secure systems ($6^{th}$ requirement, further clarifications in \cite{pcireq6}) requires merchants to firewall and conduct a code review of their public-facing web applications. These code reviews can either be done manually by developers, or through automated tools, which are generally known as \textit{static source code analyzers}. After the deployment of the reviewed code to production, another requirement is the use of \textit{WAF} (\textit{Web Application Firewall}) whose job is to stand behind the user and the web application, trying to catch and identify any known attack vectors and common vulnerabilities.
	
	The second section of interest, regarding the regular testing of secure systems ($11^{th}$ requirement, further clarifications in \cite{pcireq11}) requires merchants to conduct a penetration test at least yearly (and after every significant change to the infrastructure) by a qualified personnel. The penetration test has to cover the entire environment storing and working with the sensitive data, has to include the testing of the \textit{Network} and \textit{Application layers}, and be conducted both from an \textit{internal} and \textit{external perspective}, so that sensitive customer data is protected both from attacks from outside sources (such as hackers), and attacks from inside sources (such as rouge employees).
	
	While strict rules are set forth for protecting sensitive data, merchants tend to try and get away with the least amount of strictness they can still get compliance certified for, by skipping rules marked as ``best practice, not requirement'' and rules which they can tick on a \textit{technicality} due to the phrasing of the sentence. One such example would be the fact that for a long period of time, it was possible to \textit{trick} the code review requirement by substituting automated source code analyzers with automated penetration testing, however, since version 3.0 of the security standard, it has been clarified that penetration testing is a mandatory requirement in a different section, and as such they are not a substitute for code reviews.
	
\subsection{Government Mandated Security}
	
	The standards discussed in previous sections were all \textit{best practices} where implementing bodies would do their \textit{best effort} on complying, none of it was mandated\footnote{In 2009, Nevada (USA), then a year later, the State of Washington (USA), incorporated \textit{PCI DSS} into state law\cite{wash10}, however, the incorporated standard's sole purpose is to shield compliant parties from liability in case of a data breach.}.
	
	Besides various ``computer access acts'' around the world, making unauthorized computer access punishable by law, there is not much regulation for the relevant parties regarding storing and handling sensitive information. This results in a shifting  of the liability from the data holder with low security to the person accessing the system without authorization. The problematic part in this scenario is that this means once the infrastructure has been penetrated, the data is freely available for unauthorized consumption, whereas if stricter rules were mandated regarding storing sensitive data, it might have not been available in the first place.
	
	There is, however, at least one sector in which there is prominent government mandated security. In the USA, the field of public health is regulated by \textit{HIPAA} (\textit{Health Insurance Portability and Accountability Act}), which was signed into law\cite{hipaa96} in 1996, and amongst others, sets forth rules and requirements about confidential handling of protected health information.

\section{Software Vulnerabilities}
	
	The \textit{RFC 2828} and many \textit{NIST} publications define ``vulnerability'' as ``a flaw or weakness in system security procedures, design, implementation, or internal controls that could be exercised (accidentally triggered or intentionally exploited) and result in a security breach or a violation of the system's security policy.''\cite{rfc2828,nist80030} What this means in simplified terms is, that a vulnerability is essentially a bug in the software's or web service's code, which when \textit{exploited}, (e.g. specifying an input which was specifically crafted to be bogus and known to trigger the bug) allows users to perform actions they would otherwise not be allowed to, or access data they would otherwise not be privy to.
	
\subsection{Disclosure Procedures and Policies}
	
	Dealing with vulnerabilities found by a $3^{rd}$-party in a software or web service is a complex topic, which does not have a standard procedure defined. The person, company, or responsible industry body may have a \textit{vulnerability disclosure policy} in place if they have dealt with vulnerability disclosure in the past, however, as there is no industry standard in place, the terms in the policy will be uniquely defined as to how the vulnerability finder sees it fit.
	
	A common \textit{responsible} vulnerability disclosure practice is that the discovering body immediately notifies the vendor of the product of the vulnerability, and then either waits a given amount of days before making the vulnerability public, sometimes this may be cut short or prolonged depending on the reaction of the vendor.
	
	There are highly debated topics on what can be considered a \textit{responsible} vulnerability disclosure. One of such debate topics include whether the disclosure should be made public immediately after discovery, (\textit{a}) but with as little information as possible until the vendor fix comes, so as to protect vulnerable users from potential attackers, or (\textit{b}) it should include the full report, so as to make vulnerable users fully aware, in which situation they can actively try to defend themselves against it. 
	
	Last, but not least, in case the discovering body withheld information about the vulnerability from the public, the other debate falls on what should the grace period be for the vendor fix, and what should a vulnerability discoverer do in case the vendor does not fix it in time or cannot be contacted. If the discovered vulnerability was not made public at all, or just partially, the situation can get infinitely more complex in cases where multiple vendors are involved.
	
	Some vendors will react faster, and will try to push the update onto the users, detailing the vulnerability, while others might react slower, and will now be vulnerable, because the competing product leaked the vulnerability details with their update. In such cases, the discovering body may attempt a \textit{coordinated disclosure} and ask the vendors to withheld the fixes and updates for a few days, or until all the vendors came up with a fix.
	
	Depending on the morality of the discovering person, however, one might choose to go down the illegal route and sell the newly discovered vulnerability. On the deep web, there are marketplaces for so-called ``zero-day exploits,'' whose prices range based on the severity and impact of the vulnerability. It can go from several hundred dollars to half a million, averaging around a few thousands generally\cite{nperlroth13}.
	
	In order for high-profile companies to encourage security researchers to take the responsible disclosure route instead of the alternative, they have started creating programs called ``bug bounties.'' These programs reward vulnerability reports by offering monetary recompensation to the founder person (whose value fluctuates based on the severity and impact of the reported vulnerability) and recognition for their feat.
	
	One such notable example is Google's \textit{Vulnerability Reward Program}\cite{googlevrp15}, which pays up to tens of thousands of dollars in rewards for a vulnerability in their own services, but have also extended the bug bounty to several high-risk open-source software, for which they independently pay \$500 to \$3,133.7. Google also has a related program called \textit{Patch Reward Program}, where they pay volunteers who have fixed a security issue in a high-risk open-source application. Rewards for that program range from \$500 (for ``one-liner fixes'') to \$10,000 (for ``complicated, high-impact fixes.'')
	
\subsection{Regulatory Industry Bodies}
	
	\begin{wrapfigure}{r}{0.35\textwidth}
		\vspace{-10pt}
		\centering
		\includegraphics[scale=0.75]{cert.png}
		\caption{CERT/CC Logo}
	\end{wrapfigure}
	
	One of the responsible industry bodies in the United States is \textit{CERT/CC} (\textit{Computer Emergency Response Team Coordination Center}) which was created by \textit{DARPA} (\textit{Defense Advanced Research Projects Agency}) in November 1988 in order to be the first organization of its kind. The need for the organization was created by the first ever computer virus distributed over the Internet, namely the \textit{Morris worm}\cite{cert15}, which was the first of its kind, generating notable mainstream media attention, and resulting in the first ever arrest related to computer abuse/fraud laws in history.
	
	CERT/CC has their own policy regarding vulnerability disclosure, namely: notify the vendor as soon as possible, and disclose the report within 45 days, regardless whether the vendor has fixed the issue, or not.
	
	In Romania, \textit{CERT-RO} (\textit{Centrul Național de Răspuns la Incidente de Securitate Cibernetică}) was established in the May of 2011, through the government decision H.G. 494/2011\cite{certro12}. Its mission is to provide a national infrastructure for identification, analysis and prevention of cybernetic incidents.
	
	In Hungary, \textit{GovCERT-Hungary} (\textit{Kormányzati Eseménykezelő Központ}) was established in the April of 2013\cite{certhu13}, assuming the role of the responsible industry body for providing relevant services.
	
	Similarly, a response team is available on the European Union level. \textit{CERT-EU} (\textit{Computer Emergency Response Team European Union Task Force}) was established on the November of 2012\cite{certeu13}, via mandated EU Commission decision. This body acts as a separate response team, meaning it does not exist solely to amalgamate reports of member countries' response teams.
	
\subsection{Vulnerability Databases} \label{ssec:vulndbs}
	
	One of the projects sponsored by CERT/CC is \textit{CVE} (\textit{Common Vulnerabilities and Exposures}), which provides a reference method for publicly know and tracked vulnerabilities. \textit{NIST} (\textit{National Institute of Standards and Technology}) runs a website called \textit{NVD} (\textit{National Vulnerability Database}) which is a repository of public vulnerabilities represented in such a way as to allow for automatic consumption by vulnerability management software\cite{nvd15}.
	
	The feed of public vulnerabilities available for consumption in the aforementioned paragraph is called \textit{SCAP} (\textit{Security Content Automation Protocol}) and contains multiple components for each entry:
	
	\begin{itemize}
		\item \textit{Common Vulnerabilities and Exposures} (\textit{CVE}) -- Vulnerability reference standard.
		\item \textit{Common Configuration Enumeration} (\textit{CCE}) -- Unique identifier provider for system configuration in order to facilitate easy misconfiguration testing.
		\item \textit{Common Platform Enumeration} (\textit{CPE}) -- Standardized method for classifying and identifying applications, operating systems and hardware devices present on a system.
		\item \textit{Common Weakness Enumeration} (\textit{CWE}) -- Provides common language for identifying the type and source of the vulnerability.
		\item \textit{Common Vulnerability Scoring System} (\textit{CVSS}) -- Standard metric which allows measurement of the vulnerability's impact.
		\item \textit{Extensible Configuration Checklist Description Format} (\textit{XCCDF}) -- XML-based format for providing security checklists.
		\item \textit{Open Vulnerability and Assessment Language} (\textit{OVAL}) -- Provides language for encoding vulnerability details in order to aid internationalization.
	\end{itemize}
	
	These components will be further discussed in the section regarding the implementation of the vulnerability assessment engine.
	
\subsection{Vulnerability Risk Analysis} \label{ssec:vulnriskanal}

	During the project planning phase or later down the line when a vulnerability is discovered either during development or via penetration testing, risk analysis may be performed in order to assess the severity of the risk using the standard risk model formula shown in equation \ref{eq:risk}. Generally, if its fix would be too expensive, (e.g. it would require breaking changes, full infrastructure rebuild, or other miscellaneous major inconveniences) the results of the risk analysis are carefully evaluated by managers, and if no immediate major threat is imminent with a huge impact that can be caused by the discovered bug, an alternative route may be chosen which is not as costly.
	
	\begin{equation} \label{eq:risk}
		\textrm{Risk} = \textrm{Probability} \cdot \textrm{Impact}
	\end{equation}
	
	The \textit{Open Web Application Security Project} has defined a risk rating methodology\cite{owasp4} specifically for vulnerabilities. The steps of risk analysis for a project are:
	
	\begin{enumerate}
	  \item Identification of Risks
	  \item Estimation of Probability
	  \item Estimation of Impact
	  \item Estimation of Severity
	  \item Decision Regarding Risk Elimination
	\end{enumerate}
	
	For the first step, in case of a web application or a project with a web application subcomponent, we can start with OWASP's Top 10\cite{owasp10} list of most common security risks. After all the possible risks have been listed, we will need to go through them one-by-one and go through steps $2-5$ individually for each.
	
	\begin{equation} \label{eq:riskprobagnt}
		\textrm{Threat Agent} = \textrm{Skill Level} + \textrm{Motive} + \textrm{Opportunity} + \textrm{Size}
	\end{equation}
	\begin{equation} \label{eq:riskprobvuln}
		\textrm{Vulnerability} = \textrm{Discovery} + \textrm{Exploitation} + \textrm{Awareness} + \textrm{Detection}
	\end{equation}
	\begin{equation} \label{eq:riskprob}
		\textrm{Probability} = \frac{(\textrm{Threat Agent} + \textrm{Vulnerability})}{8}
	\end{equation}
	
	In step 2, we estimate the probability of the risk occurring. In order to do this, we go through each factors in equations \ref{eq:riskprobagnt} and \ref{eq:riskprobvuln}, assigning them each a number on a scale of $0..9$. For example, the ``Motive'' factor is directly proportional to the reward a user might get from exploiting the vulnerability, as such, we rate 0 if no significant reward can be obtained, or 9 if major financial gain can be obtained from exploiting the vulnerability. After all the factors have been scored, we calculate the arithmetic mean as seen in equation \ref{eq:riskprob}.
	
	\begin{equation} \label{eq:riskimptech}
		\textrm{Technical} = \textrm{Confidentiality} + \textrm{Integrity} + \textrm{Availability} + \textrm{Accountability}
	\end{equation}
	\begin{equation} \label{eq:riskimpbsns}
		\textrm{Business} = \textrm{Financial} + \textrm{Reputation} + \textrm{Noncompliance} + \textrm{Privacy Violation}
	\end{equation}
	\begin{equation} \label{eq:riskimp}
		\textrm{Impact} = \frac{(\textrm{Technical} + \textrm{Business})}{8}
	\end{equation}
		
	Moving on to step 3, we calculate the impact of the risk, should it occur, from both a technical and business side. Equations \ref{eq:riskimptech} and \ref{eq:riskimpbsns} list the factors which should be considered. One important example between these factors would be ``Noncompliance,'' which might further damage the company both financially and reputation-wise. Non-compliance can lead to loss of audits, licenses, which in turn can lead to fines, loss of liability protections and inability to continue business until the company can be re-audited. For example, as discussed in section \ref{ssec:secassfinsec}, the violation of \textit{PCI compliancy} can result in fines of $\$5,000$ to $\$100,000$ per month\cite{pcicompl} by the credit card company at their own discretion. If the company has no such compliance obligations, we can rate non-compliance as a non-issue with a score of 0, or if credit card data might be leaked, a maximum score of 9 should be provided.
	
	\begin{table}[!htbp]
		\begin{minipage}{.4\linewidth}
			\centering
			\begin{tabular}{cc}
				{\bf Score} & {\bf Severity} \\
				0 to 2.$\bar{9}$ & \cellcolor[HTML]{FCFF2F}Low \\
				3 to 5.$\bar{9}$ & \cellcolor[HTML]{F8A102}Medium \\
				6 to 9 & \cellcolor[HTML]{FE0000}High
			\end{tabular}
			\caption{Score Classification}
			\label{scoreclass}
		\end{minipage}
		\begin{minipage}{.6\linewidth}
			\centering
			\begin{tabular}{ccccc}
				\multicolumn{1}{l}{} & \multicolumn{1}{l}{} & \multicolumn{3}{c}{{\bf Probability}} \\
				%\multicolumn{1}{l}{} & {\bf Severity} & \cellcolor[HTML]{EFEFEF}Low &
				\multicolumn{1}{l}{} &  & \cellcolor[HTML]{EFEFEF}Low & \cellcolor[HTML]{C0C0C0}Medium & \cellcolor[HTML]{9B9B9B}High \\
				& \cellcolor[HTML]{9B9B9B}High & \cellcolor[HTML]{F8A102}Medium & \cellcolor[HTML]{FE0000}High & \cellcolor[HTML]{FFCCC9}Critical \\
				& \cellcolor[HTML]{C0C0C0}Medium & \cellcolor[HTML]{FCFF2F}Low & \cellcolor[HTML]{F8A102}Medium & \cellcolor[HTML]{FE0000}High \\
				\multirow{-3}{*}{\rotatebox[origin=c]{90}{\bf Impact}} & \cellcolor[HTML]{EFEFEF}Low & \cellcolor[HTML]{34FF34}Note & \cellcolor[HTML]{FCFF2F}Low & \cellcolor[HTML]{F8A102}Medium
			\end{tabular}
			\caption{Vulnerability Risk Severity}
			\label{vulnrisksever}
		\end{minipage}
	\end{table}
	
	The semifinal step of the risk analysis is determining the severity of the risk/vulnerability. This can be done by taking the values obtained from the aforementioned equations, and computing the final score from the standard risk formula as shown in \ref{eq:risk}.
	
	Alternatively, a more simplified visual guide can be obtained by taking the value of the ``Probability'' and ``Impact'' factors, and classifying them according to table \ref{scoreclass}. After the severity of both factors are obtained, table \ref{vulnrisksever} allows an easy lookup of the final severity of the risk.
	
	In the final step of the process, we make a decision regarding the mitigation of the risk. In general risk management theory, if the costs of mitigating a risk outweighs the costs of incurring the losses caused by its occurrence, the risk is not mitigated.
		
\subsection{Common Vulnerability Scoring System} \label{ssec:cvss}
	
	\begin{wrapfigure}{r}{0.3\textwidth}
		\vspace{-10pt}
		\centering
		\includegraphics[scale=0.4]{cvss.png}
		\caption{CVSS Logo}
	\end{wrapfigure}
	
	NIST's \textit{CVE} database has \textit{CVSS} scores associated to their vulnerability entries. This greatly enhances the ability of the tool implemented within this thesis to aid risk analysis, as the detected vulnerabilities can be set up to automatically map onto OWASP's risk analysis (or any other similar methodology in use by the business) for easier analysis of the latest vulnerabilities that may appear on a business's infrastructure.
	
	The \textit{Common Vulnerability Scoring System}\cite{cvssv2} (\textit{CVSS}) provides the following factors for each vulnerability with an associated score:
	
	\begin{multicols}{2}
		\begin{itemize}
			\item Base
				\begin{itemize}
					\item Access Vector ($AV$)
					\item Access Complexity ($AC$)
					\item Authentication ($Au$)
					\item Confidentiality Impact ($C$)
					\item Integrity Impact ($I$)
					\item Availability Impact ($A$)
				\end{itemize}
			\item Temporal
				\begin{itemize}
					\item Exploitability ($E$)
					\item Remediation Level ($RL$)
					\item Report Confidence ($RC$)
				\end{itemize}
			\item Environmental
				\begin{itemize}
					\item Collateral Damage Potential ($CDP$)
					\item Target Distribution ($TD$)
					\item Confidentiality Requirement ($CR$)
					\item Integrity Requirement ($IR$)
					\item Availability Requirement ($AR$)
				\end{itemize}
		\end{itemize}
	\end{multicols}
	
	\begin{equation} \label{eq:cvssexp}
		\textrm{Exploitability} = 20 \cdot \textrm{Access Complexity} \cdot \textrm{Authentication} \cdot \textrm{Access Vector}
	\end{equation}
	\begin{equation} \label{eq:cvssimp}
		\textrm{Impact} = 10.41 \cdot (1 - (1 - \textrm{Conf.Impact}) \cdot (1 - \textrm{Integ.Impact}) \cdot (1 - \textrm{Avail.Impact}))
	\end{equation}
	\begin{equation} \label{eq:cvss}
		\textrm{Score} = (0.6 \cdot \textrm{Impact} + 0.4 \cdot \textrm{Exploitability} - 1.5) \cdot
		\begin{cases}
			1.176, & \text{if Impact} > 0\\
			0, & \text{otherwise}
		\end{cases}
	\end{equation}
	
	As with the equations discussed in section \ref{ssec:vulnriskanal}, the ``Probability'' factor seen in equation \ref{eq:riskprob} is the functional equivalent of the ``Exploitability'' factor in equation \ref{eq:cvssexp}, similarly so are the ``Impact'' factors between equations \ref{eq:riskimp} and \ref{eq:cvssimp}.
	
	The final score given by equation \ref{eq:cvss} is on the scale of $0..1$, and its components can be used after scaling to $0..9$ in order to determine the severity of a risk by using table \ref{scoreclass} to classify it, which can then be looked up in table \ref{vulnrisksever}.
	
	Since the application implemented in the scope of this thesis reports CVSS scores for automatically detected fresh CVE vulnerabilities, it speeds up the risk analysis and decision making process, as managers can determine the severity of a newly discovered vulnerability in their systems and can act fast, if required, in cases where involving a security engineer would take much more time than desired in a critical situation.
	
\section{Vulnerability Assessment}
	
	\textit{Vulnerability assessment} is the process of identifying and quantifying[\ref{ssec:vulnriskanal}] of the vulnerabilities present within an infrastructure.
	
	In order to ensure the continuous security of an application, server or whole infrastructure, proactive measures need to be taken by the competent bodies. These measures generally include periodical scanning of the infrastructure in order to identify possible attack surfaces and test against newly discovered vulnerabilities.
	
\subsection{Static Code Analysis}
	
	One of the ways this can be carried out is through \textit{static analysis} of the source code. This is generally done by an automated tool, and then a software developer goes through the results, reviewing and evaluating the possibly erroneous code in the meantime.
	
	Static analyzers process the source code of the application, doing lexical analysis, semantic analysis, type inference, constraint analysis, and so on. Simply put, they are looking for common mistakes there were either introduced by accidentally overlooking things on the developer's part (such as variable value assignment (=) instead of comparison (==) in \textit{if} statements) or parts that would possibly behave differently than the developer intended due to various language features (such as loose comparison type juggling/inference issues.)
	
	Depending on their feature set, static analyzers may also evaluate the \textit{control flow} of a code in order to try and determine if branches exist that would result in an unwanted behavior. Another feature can be \textit{taint analysis}, which observes the evolution of variables that have user-provided input in order to determine if any input can cause issues later on in the code. In any case, code is not executed, only the source is analyzed, which introduces some limitations.
	
	Using static analysis tools have their pros and cons, for example, they can be enforced by integrating it into the build process, but they also have cons, for example, not being able to analyze binaries that have been provided without a source code, or the fact that pattern matching cannot account for everything, resulting in \textit{false negatives}. (Also known as, malicious code that was analyzed but not deemed malicious.)
	
\subsection{Fuzz Testing}
	
	A similar software testing technique that has proven useful in the field of security is \textit{fuzz testing}. This technique feeds random malformed data to the software as input, and observes the behavior of the software as a result.
	
	While this technique is not necessarily popular, it has been used quite successfully in the past by security researchers to automatically weed out bugs in numerous applications.\cite{mzalewski15} The use of randomly generated data which breaks assumptions is very successful in confusing/breaking the state machines of the parser being tested, and potentially leading to unstability during runtime or software crash. This is essentially ``vulnerability scanning by bruteforce.''
	
\subsection{Vulnerability Scanning}
	
\subsubsection{Penetration Testing}
	
	The most offensive vulnerability assessment technique is \textit{penetration testing}, which simulates real-life attacks on an infrastructure.
	
	Vulnerability scanning works well with binaries whose source is not provided, as it only simulates \textit{malicious} user interaction, and does not do code analysis. This technique also works well against live production servers, and as such fully deployed infrastructures can be scanned for vulnerabilities.
	
	\noindent Testing may be done against:
	
	\begin{itemize}
		\item port on the server -- testing for applied patches and misconfiguration of a single service (e.g. an SMTP server);
		\item web application -- crawling and analyzing the security of a whole web application through blind exploitation;
		\item entire server -- scanning all the ports and running the proper vulnerability analysis for each protocol based on their service banner;
		\item entire network -- scanning all the servers within the network, to ensure none of them are vulnerable or compromised in an environment in which sensitive data might be transferred.
	\end{itemize}
	
	\noindent Testing may also be done from various perspectives:
	
	\begin{itemize}
		\item public -- in order to determine attack vectors from the perspective of an outsider (e.g. vulnerability of public-facing IPs);
		\item consumer -- to determine attack surfaces for an authenticated non-privileged user (e.g. logged-in consumer of a banking web application);
		\item insider -- to determine the damages that can be caused by insiders (e.g. rogue employees).
	\end{itemize}
	
\subsubsection{Intrusion Detection/Prevention Systems}
	
	Penetration testing is an \textit{active} vulnerability scanning technique which simulates real-life attacks on the infrastructure, however a \textit{passive} version of this technique exists under the name of \textit{IDS}/\textit{IPS}. (\textit{Intrusion Detection/Prevention System})
	
	These systems sit between the user and the application, sniffing and analyzing traffic for potential red flags. This method is rather limited, as it cannot detect vulnerabilities in the system, with which a user has not yet interacted with due to its limited data source being only the network traffic. Another downside of this technique is that an exploitation might slip through even in the strictest setting of the IPS, as the analyzed network traffic might simply be identified as false negative. As such, preventive measures were not taken against the traffic, and the exploitation was successful.
	
\section{Implementation}

\subsection{Protocol Tokenization}
	
	In order to improve the quality of the input for the CPE matcher component (further discussed in \ref{ssec:matchcpe}) and thereby minimizing the chances of false positives, the application makes a best effort to try recognizing and tokenizing the extracted service banners.
	
	The server replies are not fully parsed using a protocol-aware parser, instead it aims to either \textit{a)} extract server names, versions and operating system tags, or if that is not possible, \textit{b)} clean any known protocol strings, leaving only implementation-specific strings in the service banner.
	
	Currently there are two protocol tokenizers implemented, and these are run in order of protocol popularity when a service banner needs to be cleaned. An API is exposed which does this, \mintinline{cpp}{ProtocolTokenizer::AutoTokenize(const std::string& banner)}.
	
	The first tokenizer is \mintinline{cpp}{HttpTokenizer}, which decides whether the specified service banner contains a valid HTTP header, and if so, proceeds to tokenize it. During tokenization, it will try to extract product names and version numbers from the appropriate places.
	
	The HTTP protocol has the `Server' and `X-Powered-By' header fields, which are generally used by software to indicate their name and version number. Unfortunately, the exact listing methodology is not standardized, as such different software may use different separators and notation to indicate their existence, version number, any vendor patches and possibly the operating system. Since these fields may have multiple products listed, the tokenizer makes sure to extract all the product names including any associated version numbers into separate tokens.
	
	\begin{listing}[H]
		\begin{minted}{http}
			HTTP/1.1 200 OK
			Server: nginx/1.9.12 (Ubuntu)
			X-Powered-By: PHP/5.6.19
			Date: Fri, 11 Mar 2016 16:04:07 GMT
			Connection: close
		\end{minted}
		\caption{Example HTTP service banner}
		\label{httpsvcbnr}
	\end{listing}
	
	The HTTP service banner shown in listing \ref{httpsvcbnr} is produced by nginx 1.9.12 with PHP 5.6.19 installed on a Ubuntu distribution. When processed by the implemented tokenizer, it will produce the elements shown in listing \ref{httpsvcbnrtokens}.
	
	\begin{listing}[H]
		\begin{minted}{py}
			[
				// token,           later mapped to,           by component
				"nginx/1.9.12",  // cpe:/a:nginx:nginx:1.9.12, CpeDictionaryMatcher
				"Ubuntu",        // cpe:/o:canonical:ubuntu,   OpSysMatcher
				"PHP/5.6.19"     // cpe:/a:php:php:5.6.19,     CpeDictionaryMatcher
			]
		\end{minted}
		\caption{Extracted tokens from banner in listing \ref{httpsvcbnr}}
		\label{httpsvcbnrtokens}
	\end{listing}
	
	However, if the service banner being analyzed does not contain a valid HTTP header, the next tokenizer in order of protocol popularity to be tried is the \mintinline{cpp}{ThreeDigitTokenizer}, hereinafter referred to as the ``SMTP tokenizer'' for simplicity's sake.
	
	The ``three-digit'' tokenizer is a general purpose solution for parsing protocols which use a three-digit response in their protocol to the indicate message type/category of a given server reply. Such protocols include SMTP, NNTP, FTP and a few more. For these protocols, however, unfortunately there is no standardized way to announce server name and version (like the `Server' header in the HTTP protocol) and as such the server name is generally casually announced in the informational level welcome message part of the service banner. The informational messages are generally within the range of $200-299$, however this might vary depending on the actual protocol.
	
	\begin{listing}[H]
		\begin{minted}{matlab}
			220 example.com ESMTP Exim 4.87 #2 Fri, 11 Mar 2016 16:05:06 +0000
		\end{minted}
		\caption{Example SMTP service banner}
		\label{smtpsvcbnr}
	\end{listing}
		
	The SMTP service banner shown in listing \ref{smtpsvcbnr} is produced by Exim 4.87 listening on port 25. This banner is sent as a `greeting' as soon as the client connects to the server. This is favorable, since no further protocol probes are required to be sent in order to get a processable service banner. When this banner is processed by the implemented tokenizer, it will produce the elements shown in listing \ref{smtpsvcbnrtokens}.
		
	\begin{listing}[H]
		\begin{minted}{py}
			[
				// token,                later mapped to,       by component
				"ESMTP Exim 4.87 #2", // cpe:/a:exim:exim:4.87, CpeDictionaryMatcher
			]
		\end{minted}
		\caption{Extracted tokens from banner in listing \ref{smtpsvcbnr}}
		\label{smtpsvcbnrtokens}
	\end{listing}
	
	It should be noted that the ``perfect'' token would be \mintinline{matlab}{Exim 4.87}, however as previously mentioned, the server name and version are not clearly advertised. As such, the processing of the banner starts by removing the protocol-specific strings, namely the response code (\mintinline{matlab}{220}), the host name (\mintinline{py}{example.com}), and the date (\mintinline{matlab}{Fri, 11 Mar 2016 16:05:06 +0000}). This leaves us with the implementation-specific string of \mintinline{matlab}{ESMTP Exim 4.87 #2}.
	
	The tokenizer implementation will try to remove as much non-implementation-specific tokens as possible, however in cases where a specific element cannot be determined with a high degree of certainty whether it is a protocol or implementation-specific string, the tokenizer will instead leave it in. This decision was made in order to ensure that the tokenizer does not remove any elements which are required for the CPE matcher during entry matching. If an element is left in falsely, it does not affect the scoring of the CPE matcher, however, if it was falsely removed, it could completely prevent the matching of that entry.
	
	If all of the implemented tokenizers fail to process a service banner, it will be sent to the next stage of discovery (usually to component described in \ref{ssec:matchcpe}) as one token, containing the whole service banner.
	
\subsection{Pattern Matching of Service Banners}

	The purpose of the \mintinline{cpp}{ServiceRegexMatcher} component of the application is to take the original full service banner (without any tokenization) as an input, and match it against a database of regular expressions, which in turn are mapped to their own CPE names.

	\begin{listing}[H]
		\begin{minted}{matlab}
			^HTTP/1\.[01] \d{3}.*\r\nServer: nginx(?:/([\d.]+))?
		\end{minted}
		\caption{Example regular expression to match \mintinline{matlab}{cpe:/a:nginx:nginx}}
		\label{nginxregex}
	\end{listing}
	
	The example regular expression in listing \ref{nginxregex} matches against the response headers produced by the HTTP server software ``nginx''. See the service banner in listing \ref{httpsvcbnr} for an example that would be matched. Furthermore, the listed regular expression contains an optional capture group, which captures the version number. If the version number is listed in the service banner, the matcher component would return the CPE name \mintinline{matlab}{cpe:/a:nginx:nginx:1.9.12}, while without a version number listed, it will still return the CPE name \mintinline{matlab}{cpe:/a:nginx:nginx}.
	
	This behavior is different from the matcher described in section \ref{ssec:matchcpe}: whereas here a CPE name can be produced with high confidence with or without a known version number, the CPE dictionary-based matcher \textit{requires} a known version number, since it plays a pivotal role in the identifying and scoring process.
	
	While the example presented in listing \ref{nginxregex} is rather straight-forward, the pattern matcher method can be used in a more subtle way, for example to match software which are not advertising their name or version number.
	
	\begin{listing}[H]
		\begin{minted}{matlab}
			^554 SMTP synchronization error\r\n
		\end{minted}
		\caption{Example regular expression to match \mintinline{matlab}{cpe:/a:exim:exim}}
		\label{eximregex}
	\end{listing}
	
	The example presented in listing \ref{eximregex} is a regular expression which matches an error message produced by the SMTP server software ``exim''. The reason why it is possible to determine this fact with a high confidence, is because exim is the only software returning this exact error message verbatim. Other SMTP servers will have a similar error message for this problem, with the same error code, but not with this same exact error message, as the messages themselves are not standardized byte-by-byte.
	
	\begin{multicols}{2}
		\begin{listing}[H]
			\begin{minted}{matlab}
				220 example-1.com ESMTP Sat, 12 Mar 2016 17:14:06 +0000
				EHLO client-1.com
				250-example-1.com Hello client-1.com [2a02:2f07:d18d:1100::cake]
				250-SIZE 52428800
				250-8BITMIME
				250-PIPELINING
				250-STARTTLS
				250-PRDR
				250 HELP
			\end{minted}
			\caption{Exim $\ge 4.83$}
			\label{eximwiprdr}
		\end{listing}
		\begin{listing}[H]
			\begin{minted}{matlab}
				220 example-2.com ESMTP Sat, 12 Mar 2016 16:12:25 +0000
				EHLO client-2.com
				250-example-2.com Hello client-2.com [2a02:2f07:d18d:1100::cake]
				250-SIZE 20971520
				250-8BITMIME
				250-PIPELINING
				250-AUTH PLAIN LOGIN
				250-STARTTLS
				250 HELP
			\end{minted}
			\caption{Exim $< 4.83$}
			\label{eximwoprdr}
		\end{listing}
	\end{multicols}
	
	It is even possible to associate a version number to the software behind the port. For example, exim has implemented ``SMTP Service Extension for Per-Recipient Data Responses'' in version 4.83, and it advertises this capability as `PRDR' after the handshake, as seen in listing \ref{eximwiprdr} versus the handshake of an older version in listing \ref{eximwoprdr}.
	
	A regular expression can be written to inspect the advertised capability list, and make an educated guess stating that the version of the software is 4.83 or older. This can be further improved by creating a pattern which matches a change which only applies to versions 4.86 and older, at which point we can deduce that the inspected service banner was produced by exim between the versions of $4.83-4.86$.
	
	For open-source software, it is possible to compare the source between different releases and check which publicly visible string changed, in order to write a pattern for detecting that range of versions. Building such a database of patterns, however, is beyond the scope of this project, and would be more suited for a community-sourced project.
	
\subsection{Matching of CPE Tokens in Service Banners} \label{ssec:matchcpe}

	Related work \cite{shovat15}.

\newpage
\section{Bibliography}

	\begingroup
	\renewcommand{\section}[2]{}
	\renewcommand{\markboth}[2]{}
		\bibliography{thesis}
		\bibliographystyle{thesis}
	\endgroup

\end{document}